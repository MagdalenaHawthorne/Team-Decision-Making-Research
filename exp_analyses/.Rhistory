independence_of_manipulations <- influence_check %>%
filter(group_structure == "h")
t.test(coefficient_of_variation ~ TMS, data = independence_of_manipulations)
# => neither the interaction nor the direct comparison of hierarchical_TMS with hierarchical_NoTMS are significant!!
# average influence by participant
leader_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
mutate(infl =
case_when(
id == 1  ~ mean(influence_p1),
id == 2  ~ mean(influence_p2),
id == 3  ~ mean(influence_p3)
)
)
t.test(infl ~ `leader?`, data=leader_check)
# average responsibility by participant
leader_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
mutate(infl = case_when(
id == 1  ~ mean(influence_p1),
id == 2  ~ mean(influence_p2),
id == 3  ~ mean(influence_p3)
),
resp =  case_when(
id == 1  ~ mean(respon_p1),
id == 2  ~ mean(respon_p2),
id == 3  ~ mean(respon_p3)
)
)
t.test(resp ~ `leader?`, data=leader_check)
View(leader_check)
# average responsibility by participant
responsibility_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
summarise(aggr_resp_p1 = mean(respon_p1), aggr_resp_p2 = mean(respon_p2), aggr_resp_p3 = mean(respon_p3))
View(responsibility_check)
# collapse aggregated responsibility scores to create a single vector
responsibility_check <- responsibility_check %>%
gather('aggr_resp_p1', 'aggr_resp_p2', 'aggr_resp_p3', key = "participant", value = "avg_respon")
responsibility_check %>%
arrange(group)
# calculate mean and standard deviation of the average responsibility per group
responsibility_check <- responsibility_check %>%
group_by(group, group_structure, TMS) %>%
summarise(responsibility = mean(avg_respon), sd_respon = sd(avg_respon))
# coefficient of variation for responsibility => perceived responsibility disparity
responsibility_check <- responsibility_check %>%
group_by(group, group_structure, TMS) %>%
mutate(coefficient_respon = sd_respon/responsibility)
# t-test
responsibility_check <- responsibility_check %>% ungroup()
t.test(coefficient_respon ~ group_structure, alternative = "greater", data = responsibility_check)
cohensD(coefficient_respon ~ group_structure, data = responsibility_check)
# violation of normality?
describe(responsibility_check$coefficient_respon)
ggplot(responsibility_check, aes(coefficient_respon)) +
geom_histogram(binwidth = 0.02)
# non-parametric test necessary, so first change character vectors to factors
responsibility_check <- responsibility_check %>%
ungroup()
responsibility_check <- mutate_at(responsibility_check, vars(group_structure, TMS), as.factor)
# finally test
oneway_test(coefficient_respon ~ group_structure, data = responsibility_check, distribution = approximate(B = 9999))
oneway_test(coefficient_respon ~ TMS, data = responsibility_check, distribution = approximate(B = 9999))
# test for significant difference
t.test(responsibility ~ group_structure, data = responsibility_check)
t.test(avg_influence ~ group_structure, data = influence_check)
manip_checks %>%
filter(TMS == 'noTMS') %>%
filter(`exp_p1?` == 'correct' & `exp_p2?` == 'correct' & `exp_p3?` == 'correct') %>% count()/120 * 100
manip_checks %>%
filter(TMS == 'TMS') %>%
filter(!`exp_p1?` == 'correct' | !`exp_p2?` == 'correct' | !`exp_p3?` == 'correct')
manip_checks %>%
filter(TMS == 'noTMS') %>%
filter(`exp_p1?` == 'correct' & `exp_p2?` == 'correct' & `exp_p3?` == 'correct') %>%
count()/120 * 100
manip_checks %>%
filter(TMS == 'TMS') %>%
filter(!`exp_p1?` == 'correct' | !`exp_p2?` == 'correct' | !`exp_p3?` == 'correct')
---
title: "Manipulation Checks"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
---
title: "Manipulation Checks"
output: pdf_document
---
---
title: "Manipulation Checks"
output: pdf_document
---
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(forcats)
library(psych)
require(lsr)
group_df <- read_csv("data/group_level_data.csv")
indiv_df <- read_csv("data/indiv_level_data.csv")
group_df <- group_df %>%
filter(!group %in% c(14, 80))
indiv_df <- indiv_df %>%
filter(!group %in% c(14, 80))
manip_checks <- indiv_df %>%
left_join(group_df, by = "group")
manip_checks <- manip_checks %>%
separate(condition, c('group_structure','TMS'), sep = '_', remove = FALSE)
manip_checks <- manip_checks %>%
mutate(binary_decision = decision == "C")
View(manip_checks)
manip_checks %>%
filter(!`formal_leader?` == "correct")
# => one person did not comply
manip_checks %>%
select(group_structure, `final_decision?`) %>%
filter(group_structure == "so", `final_decision?` == "leader")
# => everyone in the self-organized condition agreed that the group made the decision
manip_checks %>%
select(group_structure, `final_decision?`) %>%
filter(group_structure == "h", `final_decision?` == "group")
# => everyone in the hierarchichal condition agreed that the leader made the decision
# average influence by participant
influence_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
summarise(aggr_infl_p1 = mean(influence_p1), aggr_infl_p2 = mean(influence_p2), aggr_infl_p3 = mean(influence_p3))
View(influence_check)
# merge influence of three participants into one column
influence_check <- influence_check %>%
gather('aggr_infl_p1', 'aggr_infl_p2', 'aggr_infl_p3', key = "participant", value = "aggr_infl")
# order
influence_check <- influence_check %>%
arrange(group)
View(influence_check)
# calculate influence by group
influence_check <- influence_check %>%
group_by(group, group_structure, TMS) %>%
summarise(avg_influence = mean(aggr_infl, na.rm = TRUE), sd_avg_infl = sd(aggr_infl, na.rm = TRUE))
influence_check <- influence_check %>%
group_by(group, group_structure, TMS) %>%
mutate(coefficient_of_variation = sd_avg_infl/avg_influence)
library(coin)
# explore normality
ggplot(data = influence_check, aes(coefficient_of_variation)) + geom_histogram(binwidth = .04) +
facet_wrap(~group_structure)
t.test(coefficient_of_variation ~ group_structure, alternative = "greater", data = influence_check)
# one-tailed => signifikant, participants in the hierarchical condition perceived a higher discrepancy in influence
influence_check %>%
group_by(group_structure) %>%
summarise(sd = sd(coefficient_of_variation))
cohensD(coefficient_of_variation ~ group_structure, data = influence_check)
# change group structure and TMS to factors
influence_check <- influence_check %>%
ungroup()
View(influence_check)
influence_check <- mutate_at(influence_check, vars(group_structure, TMS), as.factor)
# given that the perceived influence disparity is not normally distributed, perform One-Way Permutation Test based on 9999 Monte-Carlo resamplings:
oneway_test(coefficient_of_variation ~ group_structure, data = influence_check, distribution = approximate(nresample = 9999))
# => still significant
t.test(coefficient_of_variation ~ TMS, data = influence_check)
# two-tailed => not significant
oneway_test(coefficient_of_variation ~ TMS, data = influence_check, distribution = approximate(B = 9999))
# => still not significant
# first, look at a potential interaction effect
summary(lm(coefficient_of_variation ~ group_structure * TMS, data=influence_check))
# second, test potential effect of TMS on group structure only within hierarchical groups
independence_of_manipulations <- influence_check %>%
filter(group_structure == "h")
t.test(coefficient_of_variation ~ TMS, data = independence_of_manipulations)
# => neither the interaction nor the direct comparison of hierarchical_TMS with hierarchical_NoTMS are significant!!
# average influence by participant
leader_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
mutate(infl =
case_when(
id == 1  ~ mean(influence_p1),
id == 2  ~ mean(influence_p2),
id == 3  ~ mean(influence_p3)
)
)
t.test(infl ~ `leader?`, data=leader_check)
# average responsibility by participant
leader_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
mutate(infl = case_when(
id == 1  ~ mean(influence_p1),
id == 2  ~ mean(influence_p2),
id == 3  ~ mean(influence_p3)
),
resp =  case_when(
id == 1  ~ mean(respon_p1),
id == 2  ~ mean(respon_p2),
id == 3  ~ mean(respon_p3)
)
)
t.test(resp ~ `leader?`, data=leader_check)
View(leader_check)
# average responsibility by participant
responsibility_check <- manip_checks %>%
group_by(group, group_structure, TMS) %>%
summarise(aggr_resp_p1 = mean(respon_p1), aggr_resp_p2 = mean(respon_p2), aggr_resp_p3 = mean(respon_p3))
View(responsibility_check)
# collapse aggregated responsibility scores to create a single vector
responsibility_check <- responsibility_check %>%
gather('aggr_resp_p1', 'aggr_resp_p2', 'aggr_resp_p3', key = "participant", value = "avg_respon")
responsibility_check %>%
arrange(group)
# calculate mean and standard deviation of the average responsibility per group
responsibility_check <- responsibility_check %>%
group_by(group, group_structure, TMS) %>%
summarise(responsibility = mean(avg_respon), sd_respon = sd(avg_respon))
# coefficient of variation for responsibility => perceived responsibility disparity
responsibility_check <- responsibility_check %>%
group_by(group, group_structure, TMS) %>%
mutate(coefficient_respon = sd_respon/responsibility)
# t-test
responsibility_check <- responsibility_check %>% ungroup()
t.test(coefficient_respon ~ group_structure, alternative = "greater", data = responsibility_check)
cohensD(coefficient_respon ~ group_structure, data = responsibility_check)
# violation of normality?
describe(responsibility_check$coefficient_respon)
ggplot(responsibility_check, aes(coefficient_respon)) +
geom_histogram(binwidth = 0.02)
# non-parametric test necessary, so first change character vectors to factors
responsibility_check <- responsibility_check %>%
ungroup()
responsibility_check <- mutate_at(responsibility_check, vars(group_structure, TMS), as.factor)
# finally test
oneway_test(coefficient_respon ~ group_structure, data = responsibility_check, distribution = approximate(B = 9999))
oneway_test(coefficient_respon ~ TMS, data = responsibility_check, distribution = approximate(B = 9999))
# violation of normality?
ggplot(responsibility_check, mapping = aes(responsibility)) +
geom_histogram(binwidth = 0.25)
describe(responsibility_check$responsibility)
# look at skew & kurtosis => it's fine
describe(influence_check$avg_influence)
# seems fine, too
# test for significant difference
t.test(responsibility ~ group_structure, data = responsibility_check)
# => There IS a SIGNIFICANT difference in perceived average responsibility
t.test(avg_influence ~ group_structure, data = influence_check)
# => There is NO SIGNIFICANT difference in perceived average influence
manip_checks %>%
filter(TMS == 'noTMS') %>%
filter(`exp_p1?` == 'correct' & `exp_p2?` == 'correct' & `exp_p3?` == 'correct') %>%
count()/120 * 100
require(tidyverse)
require(sjstats)
group_df <- read_csv("data/group_level_data.csv")
indiv_df <- read_csv("data/indiv_level_data.csv")
memory_df <- read_csv("data/memory_test_data.csv")
group_df <- group_df %>%
filter(!group %in% c(14, 80))
indiv_df <- indiv_df %>%
filter(!group %in% c(14, 80))
memory_df <- memory_df %>%
filter(!group %in% c(14, 80))
group_df <- group_df %>%
mutate(binary_decision = decision == "C") %>%
mutate(binary_decision_numeric = binary_decision * 1)
group_df <- group_df %>%
separate(condition, c('group_structure','TMS'), sep = '_', remove = FALSE)
group_df
group_df %>%
filter(decision == "C") %>%
count()/80 * 100
group_df %>%
filter(binary_decision == TRUE) %>%
nrow()
group_df %>%
summarise(percent_correct = sum(binary_decision_numeric)/n() * 100)
chisq.test(group_df$binary_decision, group_df$group_structure)
group_df %>%
group_by(TMS) %>%
summarise(mean(binary_decision))
group_df %>%
group_by(group_structure) %>%
summarise(mean(binary_decision * 1))
group_df %>%
group_by(group_structure, TMS) %>%
summarise(mean(binary_decision))
chisq.test(group_df$binary_decision, group_df$TMS)
ggplot(data = group_df, aes(TMS, binary_decision_numeric)) +
stat_summary(fun.y = "mean", geom = "bar")
ggplot(data=group_df, aes(group_structure, binary_decision_numeric)) +
stat_summary(fun.y = "mean", geom = "bar") +
stat_summary(fun.data = mean_cl_normal, geom = "errorbar")
ggplot(data=group_df, aes(condition, binary_decision_numeric)) +
stat_summary(fun.y = "mean", geom = "bar") +
stat_summary(fun.data = mean_cl_normal, geom = "errorbar")
plot_data <- group_df %>%
group_by(condition, group_structure, TMS) %>%
mutate(pct = mean(binary_decision_numeric))
plot_data
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = 1.5)
ggplot(data = plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(position = position_dodge(width = .9),
vjust = -0.5,
size = 3) +
scale_y_continuous(labels = scales::percent)
plot_data <- group_df %>%
group_by(condition, group_structure, TMS) %>%
mutate(pct = mean(binary_decision_numeric))
plot_data
ggplot(data = plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(position = position_dodge(width = .9),
vjust = -0.5,
size = 3) +
scale_y_continuous(labels = scales::percent)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = 1.5)
ggplot(data = plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(position = position_dodge(width = .9),
vjust = -0.5,
size = 3) +
scale_y_continuous(labels = scales::percent)
plot_data
pd <- plot_data %>%
group_by(condition, group_structure, TMS) %>%
summarise(correct_percentage = mean(binary_decision_numeric))
ggplot(data=pd, aes(group_structure, correct_percentage, fill = TMS)) +
geom_bar(stat="identity", position="dodge2") +
labs(x = "Group Structure", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
scale_x_discrete(labels = c('Hierarchical', 'Self-organized')) +
scale_fill_manual(values = c("#003f5c", "#ffa600"), labels = c('Without', 'With')) +
#scale_fill_brewer(palette="Spectral", labels = c('Without', 'With')) +
geom_text(aes(label = scales::percent(correct_percentage),
y = correct_percentage),
position = position_dodge(width = 0.9),
vjust = -1)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = 1.5)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = -1)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = -0.8)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = -0.5)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = -0.8)
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
stat_summary(fun.data = mean_cl_normal, geom = "errorbar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = -0.8)
ggplot(data = group_df, aes(TMS, binary_decision_numeric)) +
stat_summary(fun.y = "mean", geom = "bar") +
fun.data = mean_cl_normal, geom = "errorbar"
ggplot(data = group_df, aes(TMS, binary_decision_numeric)) +
stat_summary(fun.y = "mean", geom = "bar") +
fun.data = mean_cl_normal, geom = "errorbar")
ggplot(data = group_df, aes(TMS, binary_decision_numeric)) +
stat_summary(fun.y = "mean", geom = "bar") +
stat_summary(fun.data = mean_cl_normal, geom = "errorbar")
ggplot(data=plot_data, aes(condition, binary_decision_numeric, label = scales::percent(pct))) +
stat_summary(fun.y = "mean", geom = "bar") +
labs(x = "Condition", y = "Percentage of Correct Decisions") +
ylim(0, 1) +
geom_text(aes(label = scales::percent(pct),
y = pct,
group = condition),
position = position_dodge(width = 0.9),
vjust = -0.8)
time_hierarchy <- lm(duration_min ~ group_structure, data = group_df); summary(time_hierarchy)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df);
summary(time_predict)
install.packages("reghelper")
install.packages("reghelper")
filter(!`exp_p1?` == 'correct' | !`exp_p2?` == 'correct' | !`exp_p3?` == 'correct')
time_hierarchy <- lm(duration_min ~ group_structure, data = group_df); summary(time_hierarchy)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df);
summary(time_predict)
install.packages("reghelper")
reghelper::beta(time_predict, na.rm = TRUE)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df);
summary(time_predict)
reghelper::beta(time_predict, na.rm = TRUE)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df);
reghelper::beta(time_predict, na.rm = TRUE)
require(reghelper)
reghelper::beta(time_predict, na.rm = TRUE)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df);
summary(time_predict)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df)
reghelper::beta(time_predict, na.rm = TRUE)
beta(time_predict)
aov_model <- aov(duration_min ~ TMS * group_structure, data = group_df); summary(aov_model)
reghelper::beta(time_predict)
test <- group_df %>% ungroup()
require(tidyverse)
require(tidyverse)
require(sjstats)
test <- group_df %>% ungroup()
time_predict <- lm(duration_min ~ TMS * group_structure, data = test)
reghelper::beta(time_predict, na.rm = TRUE)
require(reghelper)
reghelper::beta(time_predict, na.rm = TRUE)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df)
test <- summary(time_predict)
reghelper::beta(test, na.rm = TRUE)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df)
reghelper::beta(time_predict, na.rm = TRUE)
time_predict
reghelper::beta(time_predict, na.rm = TRUE)
time_predict <- lm(duration_min ~ as.factor(TMS) * as.factor(group_structure), data = group_df)
reghelper::beta(time_predict, na.rm = TRUE)
time_predict <- lm(duration_min ~ as.factor(TMS) * as.factor(group_structure), data = group_df)
summary(time_predict)
time_predict <- lm(duration_min ~ is.factor(TMS) * is.factor(group_structure), data = group_df)
group_df_test <- group_df %>%
mutate(TMS = as.factor(TMS), group_structure = as.factor(group_structure))
time_hierarchy <- lm(duration_min ~ group_structure, data = group_df_test); summary(time_hierarchy)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df_test)
require(reghelper)
reghelper::beta(time_predict, na.rm = TRUE)
# change independent variables to factors
group_df_factor <- group_df %>%
mutate(TMS = as.factor(TMS), group_structure = as.factor(group_structure))
time_hierarchy <- lm(duration_min ~ group_structure, data = group_df_factor); summary(time_hierarchy)
time_predict <- lm(duration_min ~ TMS * group_structure, data = group_df_factor)
summary(time_predict)
install.packages("reghelper")
require(reghelper)
reghelper::beta(time_predict, na.rm = TRUE)
aov_model <- aov(duration_min ~ TMS * group_structure, data = group_df); summary(aov_model)
eta_sq(aov_model, partial = TRUE)
t.test(duration_min ~ group_structure, data = group_df)
group_df %>%
group_by(condition) %>%
summarise(m = mean(duration_min), v = sd(duration_min))
group_df %>%
group_by(group_structure) %>%
summarise(m = mean(duration_min), v = sd(duration_min))
# in the self-organized condition, does time predict outcome?
time_hierarchy_TMS <- glm(binary_decision ~ duration_min - 1 , data = group_df %>%
filter(group_structure == 'so'), family = 'binomial'); summary(time_hierarchy_TMS)
# in the hierarchical condition, does time predict outcome?
time_hierarchy_TMS <- glm(binary_decision ~ duration_min - 1 , data = group_df %>%
filter(group_structure == 'h'), family = 'binomial'); summary(time_hierarchy_TMS)
ggplot(group_df, aes(duration_min, binary_decision * 1)) +
geom_point() +
geom_smooth()
time_hierarchy_TMS <- glm(binary_decision ~ duration_min - 1, data = group_df %>%
filter(duration_min < 31), family = 'binomial'); summary(time_hierarchy_TMS)
